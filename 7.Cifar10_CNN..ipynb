{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C2AkPeapj9b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5afdd9c-ba43-4e88-eb04-b1a8d2e44f04"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train_), (x_test, y_test_) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train_)\n",
        "y_test = to_categorical(y_test_)\n",
        "\n",
        "\"\"\"## Model Definition\"\"\"\n",
        "\n",
        "from keras.models import Sequential\n",
        "model = Sequential()\n",
        "\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "model.add(Conv2D(filters=32, \n",
        "                kernel_size=(3, 3),\n",
        "                activation='relu',\n",
        "                input_shape=(32, 32, 3)))\n",
        "\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(filters=64,\n",
        "                kernel_size=(3, 3),\n",
        "                activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\"\"\"## Fitting\"\"\"\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=50, epochs=15, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['acc']) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                23050     \n",
            "=================================================================\n",
            "Total params: 42,442\n",
            "Trainable params: 42,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 1.5363 - accuracy: 0.4524 - val_loss: 1.2664 - val_accuracy: 0.5547\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 1.2014 - accuracy: 0.5811 - val_loss: 1.1050 - val_accuracy: 0.6214\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 1.0615 - accuracy: 0.6351 - val_loss: 1.0702 - val_accuracy: 0.6312\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.9799 - accuracy: 0.6639 - val_loss: 1.0210 - val_accuracy: 0.6546\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.9259 - accuracy: 0.6826 - val_loss: 0.9664 - val_accuracy: 0.6715\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.8800 - accuracy: 0.7006 - val_loss: 0.9407 - val_accuracy: 0.6764\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.8446 - accuracy: 0.7104 - val_loss: 0.9243 - val_accuracy: 0.6863\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 58s 1ms/step - loss: 0.8109 - accuracy: 0.7214 - val_loss: 0.9117 - val_accuracy: 0.6953\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 58s 1ms/step - loss: 0.7813 - accuracy: 0.7319 - val_loss: 0.9053 - val_accuracy: 0.6963\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 0.7557 - accuracy: 0.7416 - val_loss: 0.9208 - val_accuracy: 0.6934\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 0.7307 - accuracy: 0.7493 - val_loss: 0.9132 - val_accuracy: 0.6915\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 58s 1ms/step - loss: 0.7079 - accuracy: 0.7566 - val_loss: 0.8804 - val_accuracy: 0.7089\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 0.6915 - accuracy: 0.7620 - val_loss: 0.8838 - val_accuracy: 0.7068\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 0.6699 - accuracy: 0.7714 - val_loss: 0.9090 - val_accuracy: 0.7034\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 0.6538 - accuracy: 0.7766 - val_loss: 0.9068 - val_accuracy: 0.7022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-90758bbee4e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mval_loss_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    }
  ]
}